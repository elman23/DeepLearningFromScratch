{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from model.layers import Dense\n",
    "from model.losses import MeanSquaredError\n",
    "from model.metrics import eval_regression_model\n",
    "from model.networks import NeuralNetwork\n",
    "from model.operations import Sigmoid, Linear\n",
    "from model.optimizers import SGD\n",
    "from model.trainers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_2d_np(a: ndarray,\n",
    "             type: str = \"col\") -> ndarray:\n",
    "    '''\n",
    "    Turns a 1D tensor into 2D\n",
    "    '''\n",
    "\n",
    "    assert a.ndim == 1, \\\n",
    "        \"Input tensors must be 1 dimensional\"\n",
    "\n",
    "    if type == \"col\":\n",
    "        return a.reshape(-1, 1)\n",
    "    elif type == \"row\":\n",
    "        return a.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = NeuralNetwork(layers=[Dense(neurons=1,\n",
    "                                 activation=Linear())],\n",
    "                   loss=MeanSquaredError(),\n",
    "                   seed=20240304)\n",
    "\n",
    "nn = NeuralNetwork(layers=[Dense(neurons=13,\n",
    "                                 activation=Sigmoid()),\n",
    "                           Dense(neurons=1,\n",
    "                                 activation=Linear())],\n",
    "                   loss=MeanSquaredError(),\n",
    "                   seed=20240304)\n",
    "\n",
    "dl = NeuralNetwork(layers=[Dense(neurons=13,\n",
    "                                 activation=Sigmoid()),\n",
    "                           Dense(neurons=13,\n",
    "                                 activation=Sigmoid()),\n",
    "                           Dense(neurons=1,\n",
    "                                 activation=Linear())],\n",
    "                   loss=MeanSquaredError(),\n",
    "                   seed=20240304)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 61693.333\n",
      "Loss increased after epoch 20, final loss was 61693.333, using the model from epoch 10\n",
      "\n",
      "Mean absolute error: 726530.55\n",
      "\n",
      "Root mean squared error 1462970.73\n",
      "Validation loss after 10 epochs is 0.460\n",
      "Validation loss after 20 epochs is 0.424\n",
      "Validation loss after 30 epochs is 0.411\n",
      "Validation loss after 40 epochs is 0.402\n",
      "Validation loss after 50 epochs is 0.398\n",
      "\n",
      "Mean absolute error: 0.45\n",
      "\n",
      "Root mean squared error 0.63\n",
      "Validation loss after 10 epochs is 0.464\n",
      "Validation loss after 20 epochs is 0.416\n",
      "Validation loss after 30 epochs is 0.397\n",
      "Validation loss after 40 epochs is 0.381\n",
      "Validation loss after 50 epochs is 0.376\n",
      "\n",
      "Mean absolute error: 0.44\n",
      "\n",
      "Root mean squared error 0.61\n"
     ]
    }
   ],
   "source": [
    "california = fetch_california_housing()\n",
    "data = california.data\n",
    "target = california.target\n",
    "features = california.feature_names\n",
    "\n",
    "# Scaling the data\n",
    "s = StandardScaler()\n",
    "data = s.fit_transform(data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=80718)\n",
    "\n",
    "# make target 2d array\n",
    "y_train, y_test = to_2d_np(y_train), to_2d_np(y_test)\n",
    "\n",
    "trainer = Trainer(lr, SGD(lr=0.01))\n",
    "\n",
    "trainer.fit(X_train, y_train, X_test, y_test,\n",
    "            epochs=50,\n",
    "            eval_every=10,\n",
    "            seed=20190501);\n",
    "print()\n",
    "eval_regression_model(lr, X_test, y_test)\n",
    "\n",
    "trainer = Trainer(nn, SGD(lr=0.01))\n",
    "\n",
    "trainer.fit(X_train, y_train, X_test, y_test,\n",
    "            epochs=50,\n",
    "            eval_every=10,\n",
    "            seed=20190501);\n",
    "print()\n",
    "eval_regression_model(nn, X_test, y_test)\n",
    "\n",
    "trainer = Trainer(dl, SGD(lr=0.01))\n",
    "\n",
    "trainer.fit(X_train, y_train, X_test, y_test,\n",
    "            epochs=50,\n",
    "            eval_every=10,\n",
    "            seed=20190501);\n",
    "print()\n",
    "eval_regression_model(dl, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
